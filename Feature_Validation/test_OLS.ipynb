{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU+qzAgLMfm/4lvm8B+VLA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Billy-Drunkenstein/Jupiter/blob/main/Feature_Validation/test_OLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L64eWi9oxhb"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "from typing import Sequence, Union\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Tuple\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/gpfs/hddfs/shared/tzheng_ryin\"\n",
        "features_dir = \"cnfut/cnfut_snap_pool_feather\"\n",
        "targets_dir = \"cnfut/cnfut_snap_y_feather\"\n",
        "ref_headers_dir = \"cnfut/FeatureHeaders.00000000\"\n",
        "output_dir = \"cnfut_meta_matrices\"\n",
        "\n",
        "features_path = os.path.join(base_dir, features_dir)\n",
        "targets_path = os.path.join(base_dir, targets_dir)\n",
        "calendar_path = os.path.join(base_dir, \"calendar/cn_calendar\")\n",
        "reference_headers_path = os.path.join(base_dir, ref_headers_dir)\n",
        "output_path = Path(os.path.join(base_dir, output_dir))"
      ],
      "metadata": {
        "id": "ZZWsJwfmrLwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = [\"y60r05\"]"
      ],
      "metadata": {
        "id": "ayj4yTvUrOsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read"
      ],
      "metadata": {
        "id": "kHMYVs1qrPE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(calendar_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    calendar = [int(line.rstrip(\"\\n\")) for line in f]\n",
        "\n",
        "try:\n",
        "    with open(reference_headers_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ref_headers = [line.rstrip(\"\\n\") for line in f]\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(\n",
        "        \"Reference Headers Not Found: make sure FeatureHeaders.00000000 exists in cnfut directory\"\n",
        "    ) from e\n"
      ],
      "metadata": {
        "id": "sJ-sTE_yrPme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_meta_matrices(output_path, date):\n",
        "    out = Path(output_path)\n",
        "    headers_path = out / f\"FeatureHeaders.{date}\"\n",
        "    xx_path = out / f\"XX.{date}.csv\"\n",
        "    corr_path = out / f\"FeatureCorr.{date}.csv\"\n",
        "\n",
        "    # Headers: list[str]\n",
        "    with open(headers_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        headers = [line.rstrip(\"\\n\") for line in f]\n",
        "\n",
        "    # XX: np.ndarray shape (p+1, p+1)\n",
        "    XX = np.loadtxt(xx_path, delimiter=\",\")\n",
        "\n",
        "    # FeatureCorr: pd.DataFrame\n",
        "    corr = pd.read_csv(corr_path)\n",
        "\n",
        "    return headers, XX, corr\n",
        "\n",
        "\n",
        "def assemble_dates(\n",
        "    calendar: List[str], yyyymmdd: str, back_horizon: int\n",
        "):\n",
        "    if back_horizon < 0:\n",
        "        raise ValueError(\"Backtest horizon must be positive\")\n",
        "\n",
        "    if yyyymmdd not in calendar:\n",
        "        raise ValueError(f\"Date currently restricted to cn_calendar dates\")\n",
        "\n",
        "    i = calendar.index(yyyymmdd)\n",
        "    start_idx = i - (back_horizon - 1)\n",
        "    if start_idx < 0:\n",
        "        raise ValueError(\n",
        "            f\"Insufficient calendar history for {yyyymmdd} and backtest horizon {back_horizon}\"\n",
        "        )\n",
        "\n",
        "    return calendar[start_idx : i + 1]\n"
      ],
      "metadata": {
        "id": "4AFeIY0rrRE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asof = 20251030\n",
        "\n",
        "in_sample_dates = assemble_dates(calendar, asof, 30)\n",
        "\n",
        "missing = []\n",
        "broken = []\n",
        "\n",
        "for d in in_sample_dates:\n",
        "    p_headers = output_path / f\"FeatureHeaders.{d}\"\n",
        "    p_corr = output_path / f\"FeatureCorr.{d}.csv\"\n",
        "    p_xx = output_path / f\"XX.{d}.csv\"\n",
        "\n",
        "    e_headers = p_headers.exists()\n",
        "    e_corr = p_corr.exists()\n",
        "    e_xx = p_xx.exists()\n",
        "\n",
        "    n_exist = int(e_headers) + int(e_corr) + int(e_xx)\n",
        "\n",
        "    if n_exist == 0:\n",
        "        missing.append(d)\n",
        "    elif n_exist != 3:\n",
        "        broken.append(d)\n",
        "\n",
        "if broken:\n",
        "    raise FileNotFoundError(f\"Broken dates: {broken}\")\n",
        "if missing:\n",
        "    raise FileNotFoundError(f\"Missing dates: {missing}\")\n"
      ],
      "metadata": {
        "id": "2TCKuzNcrSbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assemble Meta Data"
      ],
      "metadata": {
        "id": "ylW4qETyrVER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = len(ref_headers)\n",
        "fid_ref = [f\"F{i}\" for i in range(p)]\n",
        "prefixes = [f\"Y{k}_\" for k in range(len(target_cols))]\n",
        "\n",
        "xx = np.zeros((p, p), dtype=np.float32)\n",
        "\n",
        "N = {pref: np.int64(0) for pref in prefixes}\n",
        "x_sum = {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes}\n",
        "y_sum = {pref: np.float32(0.0) for pref in prefixes}\n",
        "yy = {pref: np.float32(0.0) for pref in prefixes}\n",
        "xy = {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes}\n",
        "\n",
        "for d in in_sample_dates:\n",
        "    headers_path = output_path / f\"FeatureHeaders.{d}\"\n",
        "    corr_path = output_path / f\"FeatureCorr.{d}.csv\"\n",
        "    xx_path = output_path / f\"XX.{d}.csv\"\n",
        "\n",
        "    with headers_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        headers = [line.strip() for line in f if line.strip()]\n",
        "    if headers != ref_headers:\n",
        "        raise ValueError(f\"FeatureHeaders mismatch at {d}\")\n",
        "\n",
        "    XX_d = pd.read_csv(xx_path, header=None).to_numpy(dtype=np.float32, copy=False)\n",
        "    if XX_d.shape != (p + 1, p + 1):\n",
        "        raise ValueError(f\"XX shape mismatch: expected {(p+1, p+1)}, got {XX_d.shape}\")\n",
        "\n",
        "    XTX_d = XX_d[1:, :p]\n",
        "    if XTX_d.shape != (p, p):\n",
        "        raise ValueError(f\"Bad XTX block at {d}: expected {(p, p)}, got {XTX_d.shape}\")\n",
        "\n",
        "    if not np.all(XX_d[1:, p] == 0):\n",
        "        raise ValueError(\"Unexpected nonzero entries in XX last column\")\n",
        "\n",
        "    xx += XTX_d\n",
        "\n",
        "\n",
        "    df = pd.read_csv(corr_path)\n",
        "\n",
        "    if \"fid\" not in df.columns:\n",
        "        raise ValueError(f\"Missing fid {d}\")\n",
        "    if df.shape[0] != p:\n",
        "        raise ValueError(\"Feature Column Count Mismatch\")\n",
        "    if df[\"fid\"].tolist() != fid_ref:\n",
        "        raise ValueError(f\"fid mismatch {d}\")\n",
        "\n",
        "    for pref in prefixes:\n",
        "        need = [f\"{pref}N\", f\"{pref}X\", f\"{pref}XX\", f\"{pref}Y\", f\"{pref}YY\", f\"{pref}XY\"]\n",
        "        miss = [c for c in need if c not in df.columns]\n",
        "        if miss:\n",
        "            raise ValueError(f\"Missing columns {d}: {miss}\")\n",
        "\n",
        "        N_d = np.int64(df[f\"{pref}N\"].iloc[0])\n",
        "        X_d = df[f\"{pref}X\"].to_numpy(dtype=np.float32, copy=False)\n",
        "        Y_d = np.float32(df[f\"{pref}Y\"].iloc[0])\n",
        "        YY_d = np.float32(df[f\"{pref}YY\"].iloc[0])\n",
        "        XY_d = df[f\"{pref}XY\"].to_numpy(dtype=np.float32, copy=False)\n",
        "\n",
        "        N[pref] += N_d\n",
        "        x_sum[pref] += X_d\n",
        "        y_sum[pref] += Y_d\n",
        "        yy[pref] += YY_d\n",
        "        xy[pref] += XY_d"
      ],
      "metadata": {
        "id": "x-M1odWSrT0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLS"
      ],
      "metadata": {
        "id": "aAjnQbxFrY-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "betas = {}\n",
        "metrics = {}\n",
        "\n",
        "xx64 = xx.astype(np.float64, copy=False)\n",
        "\n",
        "for pref in prefixes:\n",
        "    n = int(N[pref])\n",
        "    assert n > 0\n",
        "\n",
        "    xs = x_sum[pref].astype(np.float64, copy=False)\n",
        "    ys = float(y_sum[pref])\n",
        "    yty = float(yy[pref])\n",
        "    xty = xy[pref].astype(np.float64, copy=False)\n",
        "\n",
        "    G = np.empty((p + 1, p + 1), dtype=np.float64)\n",
        "    G[0, 0] = n\n",
        "    G[0, 1:] = xs\n",
        "    G[1:, 0] = xs\n",
        "    G[1:, 1:] = xx64\n",
        "\n",
        "    g = np.empty((p + 1,), dtype=np.float64)\n",
        "    g[0] = ys\n",
        "    g[1:] = xty\n",
        "\n",
        "    beta = np.linalg.solve(G, g)\n",
        "\n",
        "    betaTg = float(beta @ g)\n",
        "    sse = yty - betaTg\n",
        "\n",
        "    if sse < 0 and sse > -1e-6 * max(1.0, yty):\n",
        "        sse = 0.0\n",
        "\n",
        "    mse = sse / n\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    ybar = ys / n\n",
        "    tss = yty - n * (ybar ** 2)\n",
        "    if tss <= 0:\n",
        "        r2 = np.nan\n",
        "    else:\n",
        "        r2 = 1.0 - (sse / tss)\n",
        "\n",
        "    betas[pref] = beta.astype(np.float64, copy=False)\n",
        "    metrics[pref] = {\n",
        "        \"N\": n,\n",
        "        \"SSE\": sse,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R2\": r2,\n",
        "    }"
      ],
      "metadata": {
        "id": "ka9vEyQBrXsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uknVdKhpradp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}