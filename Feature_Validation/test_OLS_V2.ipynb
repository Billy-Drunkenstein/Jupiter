{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOiUWa1E2fcDOVyJju5TXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Billy-Drunkenstein/Jupiter/blob/main/Feature_Validation/test_OLS_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM542O4gQbhM"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "from typing import Sequence, Union, Literal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Tuple\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tqdm import tqdm\n",
        "from __future__ import annotations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/gpfs/hddfs/shared/tzheng_ryin\"\n",
        "features_dir = \"cnfut/cnfut_snap_pool_feather\"\n",
        "targets_dir = \"cnfut/cnfut_snap_y_feather\"\n",
        "ref_headers_dir = \"cnfut/FeatureHeaders.00000000\"\n",
        "output_dir = \"cnfut_meta_matrices\"\n",
        "\n",
        "features_path = os.path.join(base_dir, features_dir)\n",
        "targets_path = os.path.join(base_dir, targets_dir)\n",
        "calendar_path = os.path.join(base_dir, \"calendar/cn_calendar\")\n",
        "reference_headers_path = os.path.join(base_dir, ref_headers_dir)\n",
        "output_path = Path(os.path.join(base_dir, output_dir))"
      ],
      "metadata": {
        "id": "UmMtrcIVQ_Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = [\"y60r05\"]"
      ],
      "metadata": {
        "id": "eHJjjmIzRHY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read"
      ],
      "metadata": {
        "id": "pyndGL8WRJe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(calendar_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    calendar = [int(line.rstrip(\"\\n\")) for line in f]\n",
        "\n",
        "try:\n",
        "    with open(reference_headers_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ref_headers = [line.rstrip(\"\\n\") for line in f]\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(\n",
        "        \"Reference Headers Not Found: make sure FeatureHeaders.00000000 exists in cnfut directory\"\n",
        "    ) from e"
      ],
      "metadata": {
        "id": "dVH5H8bsRKTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_meta_matrices(\n",
        "    output_path: str | Path,\n",
        "    date: int,\n",
        "    *,\n",
        "    ref_headers: Sequence[str],\n",
        "    target_cols: Sequence[str],\n",
        "):\n",
        "    out = Path(output_path)\n",
        "    p = len(ref_headers)\n",
        "\n",
        "    headers_path = out / f\"FeatureHeaders.{date}\"\n",
        "    xx_path = out / f\"XX.{date}.csv\"\n",
        "    corr_path = out / f\"FeatureCorr.{date}.csv\"\n",
        "\n",
        "    e_headers = headers_path.exists()\n",
        "    e_xx = xx_path.exists()\n",
        "    e_corr = corr_path.exists()\n",
        "    n_exist = int(e_headers) + int(e_xx) + int(e_corr)\n",
        "\n",
        "    if n_exist == 0:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Missing date {date}: none of Headers/XX/Corr exist under {out}\"\n",
        "        )\n",
        "\n",
        "    if n_exist != 3:\n",
        "        missing_ids = []\n",
        "        if not e_headers:\n",
        "            missing_ids.append(\"Headers\")\n",
        "        if not e_xx:\n",
        "            missing_ids.append(\"XX\")\n",
        "        if not e_corr:\n",
        "            missing_ids.append(\"Corr\")\n",
        "        raise FileNotFoundError(f\"Broken date {date}: missing {missing_ids}\")\n",
        "\n",
        "    # ---------- Headers ----------\n",
        "    try:\n",
        "        with headers_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "            headers = [line.strip() for line in f if line.strip()]\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Failed reading Headers at {date}\") from e\n",
        "\n",
        "    if headers != list(ref_headers):\n",
        "        raise ValueError(f\"Headers mismatch at {date}\")\n",
        "\n",
        "    # ---------- XX ----------\n",
        "    try:\n",
        "        XX_d = pd.read_csv(xx_path, header=None).to_numpy(dtype=np.float32, copy=False)\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Failed reading XX at {date}\") from e\n",
        "\n",
        "    exp_shape = (p + 1, p + 1)\n",
        "    if XX_d.shape != exp_shape:\n",
        "        raise ValueError(f\"XX shape mismatch at {date}: expected {exp_shape}, got {XX_d.shape}\")\n",
        "\n",
        "    if not np.all(XX_d[1:, p] == 0):\n",
        "        raise ValueError(f\"Unexpected nonzero entries in XX last column at {date}\")\n",
        "\n",
        "    # ---------- Corr ----------\n",
        "    try:\n",
        "        df = pd.read_csv(corr_path)\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Failed reading Corr at {date}\") from e\n",
        "\n",
        "    if \"fid\" not in df.columns:\n",
        "        raise ValueError(f\"Missing column 'fid' at {date}\")\n",
        "\n",
        "    if df.shape[0] != p:\n",
        "        raise ValueError(f\"Feature row count mismatch at {date}: expected {p}, got {df.shape[0]}\")\n",
        "\n",
        "    fid_ref = [f\"F{i}\" for i in range(p)]\n",
        "    if df[\"fid\"].tolist() != fid_ref:\n",
        "        raise ValueError(f\"fid ordering mismatch at {date}\")\n",
        "\n",
        "    prefixes = [f\"Y{k}_\" for k in range(len(target_cols))]\n",
        "    for pref in prefixes:\n",
        "        need = [f\"{pref}N\", f\"{pref}X\", f\"{pref}XX\", f\"{pref}Y\", f\"{pref}YY\", f\"{pref}XY\"]\n",
        "        miss = [c for c in need if c not in df.columns]\n",
        "        if miss:\n",
        "            raise ValueError(f\"Missing columns at {date} for {pref}: {miss}\")\n",
        "\n",
        "    return headers, XX_d, df\n",
        "\n",
        "\n",
        "def assemble_dates(\n",
        "    calendar: Sequence[int],\n",
        "    asof: int,\n",
        "    n: int,\n",
        "    mode: Literal[\"in sample\", \"out of sample\"],\n",
        ") -> List[int]:\n",
        "    \"\"\"\n",
        "    in sample: includes asof date\n",
        "    out of sample: excludes asof date\n",
        "    \"\"\"\n",
        "    if n < 1:\n",
        "        raise ValueError(\"Include at least 1 day\")\n",
        "\n",
        "    if asof not in calendar:\n",
        "        raise ValueError(\"Date currently restricted to cn_calendar dates\")\n",
        "\n",
        "    i = calendar.index(asof)\n",
        "\n",
        "    if mode == \"in sample\":\n",
        "        start = i - (n - 1)\n",
        "        end = i + 1\n",
        "        if start < 0:\n",
        "            raise ValueError(f\"Insufficient calendar history for asof = {asof} and n = {n}\")\n",
        "        return list(calendar[start:end])\n",
        "\n",
        "    if mode == \"out of sample\":\n",
        "        start = i + 1\n",
        "        end = i + 1 + n\n",
        "        if end > len(calendar):\n",
        "            raise ValueError(f\"Insufficient forward calendar for asof = {asof} and n = {n}\")\n",
        "        return list(calendar[start:end])\n",
        "\n",
        "    raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "\n",
        "def build_windows(\n",
        "    output_path: str | Path,\n",
        "    calendar: Sequence[int],\n",
        "    asof: int,\n",
        "    lookback: int,\n",
        "    lookforward: int,\n",
        "    *,\n",
        "    ref_headers: Sequence[str],\n",
        "    target_cols: Sequence[str],\n",
        "):\n",
        "    out = Path(output_path)\n",
        "    p = len(ref_headers)\n",
        "    prefixes = [f\"Y{k}_\" for k in range(len(target_cols))]\n",
        "\n",
        "    IS_dates = assemble_dates(calendar, asof, lookback, \"in sample\")\n",
        "    OOS_dates = assemble_dates(calendar, asof, lookforward, \"out of sample\")\n",
        "\n",
        "    IS_xx = np.zeros((p, p), dtype=np.float32)\n",
        "    IS_stats = {\n",
        "        \"N\": {pref: np.int64(0) for pref in prefixes},\n",
        "        \"x_sum\": {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes},\n",
        "        \"y_sum\": {pref: np.float32(0.0) for pref in prefixes},\n",
        "        \"yy\": {pref: np.float32(0.0) for pref in prefixes},\n",
        "        \"xy\": {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes},\n",
        "    }\n",
        "\n",
        "    for d in IS_dates:\n",
        "        _, XX_d, df = read_meta_matrices(\n",
        "            out,\n",
        "            d,\n",
        "            ref_headers = ref_headers,\n",
        "            target_cols = target_cols,\n",
        "        )\n",
        "\n",
        "        XTX_d = XX_d[1:, :p]\n",
        "        if XTX_d.shape != (p, p):\n",
        "            raise ValueError(f\"Bad XTX block at {d}: expected {(p, p)}, got {XTX_d.shape}\")\n",
        "\n",
        "        IS_xx += XTX_d.astype(np.float32, copy = False)\n",
        "\n",
        "        for pref in prefixes:\n",
        "            N_d = np.int64(df[f\"{pref}N\"].iloc[0])\n",
        "            X_d = df[f\"{pref}X\"].to_numpy(dtype = np.float32, copy = False)\n",
        "            Y_d = np.float32(df[f\"{pref}Y\"].iloc[0])\n",
        "            YY_d = np.float32(df[f\"{pref}YY\"].iloc[0])\n",
        "            XY_d = df[f\"{pref}XY\"].to_numpy(dtype = np.float32, copy = False)\n",
        "\n",
        "            if X_d.shape[0] != p or XY_d.shape[0] != p:\n",
        "                raise ValueError(\n",
        "                    f\"Vector length mismatch at {d} for {pref}: expected {p}, got X = {X_d.shape}, XY = {XY_d.shape}\"\n",
        "                )\n",
        "\n",
        "            IS_stats[\"N\"][pref] += N_d\n",
        "            IS_stats[\"x_sum\"][pref] += X_d\n",
        "            IS_stats[\"y_sum\"][pref] += Y_d\n",
        "            IS_stats[\"yy\"][pref] += YY_d\n",
        "            IS_stats[\"xy\"][pref] += XY_d\n",
        "\n",
        "    OOS_xx = np.zeros((p, p), dtype=np.float32)\n",
        "    OOS_stats = {\n",
        "        \"N\": {pref: np.int64(0) for pref in prefixes},\n",
        "        \"x_sum\": {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes},\n",
        "        \"y_sum\": {pref: np.float32(0.0) for pref in prefixes},\n",
        "        \"yy\": {pref: np.float32(0.0) for pref in prefixes},\n",
        "        \"xy\": {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes},\n",
        "    }\n",
        "\n",
        "    OOS_daily = {}\n",
        "\n",
        "    for d in OOS_dates:\n",
        "        _, XX_d, df = read_meta_matrices(\n",
        "            out,\n",
        "            d,\n",
        "            ref_headers = ref_headers,\n",
        "            target_cols = target_cols,\n",
        "        )\n",
        "\n",
        "        day_xx = np.zeros((p, p), dtype=np.float32)\n",
        "        day_stats = {\n",
        "            \"N\": {pref: np.int64(0) for pref in prefixes},\n",
        "            \"x_sum\": {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes},\n",
        "            \"y_sum\": {pref: np.float32(0.0) for pref in prefixes},\n",
        "            \"yy\": {pref: np.float32(0.0) for pref in prefixes},\n",
        "            \"xy\": {pref: np.zeros((p,), dtype=np.float32) for pref in prefixes},\n",
        "        }\n",
        "\n",
        "        XTX_d = XX_d[1:, :p]\n",
        "        if XTX_d.shape != (p, p):\n",
        "            raise ValueError(f\"Bad XTX block at {d}: expected {(p, p)}, got {XTX_d.shape}\")\n",
        "\n",
        "        add_xx = XTX_d.astype(np.float32, copy = False)\n",
        "        day_xx += add_xx\n",
        "        OOS_xx += add_xx\n",
        "\n",
        "        for pref in prefixes:\n",
        "            N_d = np.int64(df[f\"{pref}N\"].iloc[0])\n",
        "            X_d = df[f\"{pref}X\"].to_numpy(dtype = np.float32, copy = False)\n",
        "            Y_d = np.float32(df[f\"{pref}Y\"].iloc[0])\n",
        "            YY_d = np.float32(df[f\"{pref}YY\"].iloc[0])\n",
        "            XY_d = df[f\"{pref}XY\"].to_numpy(dtype = np.float32, copy = False)\n",
        "\n",
        "            if X_d.shape[0] != p or XY_d.shape[0] != p:\n",
        "                raise ValueError(\n",
        "                    f\"Vector length mismatch at {d} for {pref}: expected {p}, got X = {X_d.shape}, XY = {XY_d.shape}\"\n",
        "                )\n",
        "\n",
        "            day_stats[\"N\"][pref] += N_d\n",
        "            day_stats[\"x_sum\"][pref] += X_d\n",
        "            day_stats[\"y_sum\"][pref] += Y_d\n",
        "            day_stats[\"yy\"][pref] += YY_d\n",
        "            day_stats[\"xy\"][pref] += XY_d\n",
        "\n",
        "            OOS_stats[\"N\"][pref] += N_d\n",
        "            OOS_stats[\"x_sum\"][pref] += X_d\n",
        "            OOS_stats[\"y_sum\"][pref] += Y_d\n",
        "            OOS_stats[\"yy\"][pref] += YY_d\n",
        "            OOS_stats[\"xy\"][pref] += XY_d\n",
        "\n",
        "        OOS_daily[d] = (day_xx, day_stats)\n",
        "\n",
        "    return IS_xx, IS_stats, OOS_xx, OOS_stats, OOS_daily\n",
        "\n",
        "\n",
        "def fit_from_meta(\n",
        "    IS_xx: np.ndarray,\n",
        "    IS_stats: dict,\n",
        "    *,\n",
        "    target_cols: list[str],\n",
        "):\n",
        "    prefixes = [f\"Y{k}_\" for k in range(len(target_cols))]\n",
        "\n",
        "    p = IS_xx.shape[0]\n",
        "    if IS_xx.shape != (p, p):\n",
        "        raise ValueError(f\"IS_xx must be square, got {IS_xx.shape}\")\n",
        "\n",
        "    betas = {}\n",
        "    IS_metrics = {}\n",
        "\n",
        "    xx64 = IS_xx.astype(np.float64, copy = False)\n",
        "\n",
        "    for pref in prefixes:\n",
        "        n = int(IS_stats[\"N\"][pref])\n",
        "        if n <= 0:\n",
        "            raise ValueError(f\"{pref}N must be > 0, got {n}\")\n",
        "\n",
        "        xs = IS_stats[\"x_sum\"][pref].astype(np.float64, copy = False)\n",
        "        ys = float(IS_stats[\"y_sum\"][pref])\n",
        "        yty = float(IS_stats[\"yy\"][pref])\n",
        "        xty = IS_stats[\"xy\"][pref].astype(np.float64, copy = False)\n",
        "\n",
        "        if xs.shape != (p, ):\n",
        "            raise ValueError(f\"{pref}x_sum shape mismatch: expected {(p, )}, got {xs.shape}\")\n",
        "        if xty.shape != (p, ):\n",
        "            raise ValueError(f\"{pref}xy shape mismatch: expected {(p, )}, got {xty.shape}\")\n",
        "\n",
        "        G = np.empty((p + 1, p + 1), dtype = np.float64)\n",
        "        G[0, 0] = n\n",
        "        G[0, 1:] = xs\n",
        "        G[1:, 0] = xs\n",
        "        G[1:, 1:] = xx64\n",
        "\n",
        "        g = np.empty((p + 1, ), dtype = np.float64)\n",
        "        g[0] = ys\n",
        "        g[1:] = xty\n",
        "\n",
        "        beta = np.linalg.solve(G, g)\n",
        "\n",
        "        betaTg = float(beta @ g)\n",
        "        sse = yty - betaTg\n",
        "        if sse < 0 and sse > -1e-6 * max(1.0, yty):\n",
        "            sse = 0.0\n",
        "\n",
        "        mse = sse / n\n",
        "        rmse = float(np.sqrt(mse))\n",
        "\n",
        "        ybar = ys / n\n",
        "        tss = yty - n * (ybar ** 2)\n",
        "        if tss <= 0:\n",
        "            r2 = np.nan\n",
        "        else:\n",
        "            r2 = 1.0 - (sse / tss)\n",
        "\n",
        "        betas[pref] = beta\n",
        "        IS_metrics[pref] = {\n",
        "            \"N\": n,\n",
        "            \"SSE\": float(sse),\n",
        "            \"MSE\": float(mse),\n",
        "            \"RMSE\": float(rmse),\n",
        "            \"R2\": float(r2) if np.isfinite(r2) else r2,\n",
        "        }\n",
        "\n",
        "    return betas, IS_metrics\n",
        "\n",
        "\n",
        "def score_one_window(\n",
        "    beta: np.ndarray,\n",
        "    xx: np.ndarray,\n",
        "    stats: dict,\n",
        "    *,\n",
        "    pref: str,\n",
        "):\n",
        "    xx = np.asarray(xx)\n",
        "    p = xx.shape[0]\n",
        "    if xx.shape != (p, p):\n",
        "        raise ValueError(f\"xx must be square, got {xx.shape}\")\n",
        "\n",
        "    beta = np.array(beta, dtype = np.float64)\n",
        "    if beta.shape != (p + 1, ):\n",
        "        raise ValueError(f\"beta shape mismatch: expected {(p + 1, )}, got {beta.shape}\")\n",
        "\n",
        "    n = int(stats[\"N\"][pref])\n",
        "    if n <= 0:\n",
        "        raise ValueError(\"Must have at least some samples\")\n",
        "\n",
        "    xs = stats[\"x_sum\"][pref].astype(np.float64, copy = False)\n",
        "    ys = float(stats[\"y_sum\"][pref])\n",
        "    yty = float(stats[\"yy\"][pref])\n",
        "    xty = stats[\"xy\"][pref].astype(np.float64, copy = False)\n",
        "\n",
        "    if xs.shape != (p, ):\n",
        "        raise ValueError(f\"{pref}x_sum shape mismatch: expected {(p, )}, got {xs.shape}\")\n",
        "    if xty.shape != (p, ):\n",
        "        raise ValueError(f\"{pref}xy shape mismatch: expected {(p, )}, got {xty.shape}\")\n",
        "\n",
        "    b0 = float(beta[0])\n",
        "    b = beta[1:]\n",
        "\n",
        "    xx64 = xx.astype(np.float64, copy = False)\n",
        "\n",
        "    betaT_Xty = b0 * ys + float(b @ xty)\n",
        "    betaT_XtX_beta = (b0 * b0) * n + 2.0 * b0 * float(b @ xs) + float(b @ (xx64 @ b))\n",
        "\n",
        "    sse = yty - 2.0 * betaT_Xty + betaT_XtX_beta\n",
        "    if sse < 0 and sse > -1e-6 * max(1.0, yty):\n",
        "        sse = 0.0\n",
        "\n",
        "    mse = sse / n\n",
        "    rmse = float(np.sqrt(mse))\n",
        "\n",
        "    ybar = ys / n\n",
        "    tss = yty - n * (ybar ** 2)\n",
        "    if tss <= 0:\n",
        "        r2 = np.nan\n",
        "    else:\n",
        "        r2 = 1.0 - (sse / tss)\n",
        "\n",
        "    return {\n",
        "        \"N\": n,\n",
        "        \"SSE\": float(sse),\n",
        "        \"MSE\": float(mse),\n",
        "        \"RMSE\": float(rmse),\n",
        "        \"R2\": float(r2) if np.isfinite(r2) else r2,\n",
        "    }\n",
        "\n",
        "\n",
        "def test_from_meta(\n",
        "    betas: dict,\n",
        "    OOS_xx: np.ndarray,\n",
        "    OOS_stats: dict,\n",
        "    OOS_daily: dict,\n",
        "    *,\n",
        "    target_cols: list[str],\n",
        "):\n",
        "    prefixes = [f\"Y{k}_\" for k in range(len(target_cols))]\n",
        "    out = {\"agg\": {}}\n",
        "\n",
        "    for pref in prefixes:\n",
        "        if pref not in betas:\n",
        "            raise KeyError(f\"Missing beta for {pref}\")\n",
        "\n",
        "        out[\"agg\"][pref] = score_one_window(\n",
        "            beta = betas[pref],\n",
        "            xx = OOS_xx,\n",
        "            stats = OOS_stats,\n",
        "            pref = pref,\n",
        "        )\n",
        "\n",
        "    if OOS_daily is not None:\n",
        "        out[\"daily\"] = {pref: {} for pref in prefixes}\n",
        "        OOS_dates = sorted(OOS_daily.keys())\n",
        "\n",
        "        for j, d in enumerate(OOS_dates, start = 1):\n",
        "            day_xx, day_stats = OOS_daily[d]\n",
        "            key = f\"t+{j}\"\n",
        "\n",
        "            for pref in prefixes:\n",
        "                out[\"daily\"][pref][key] = score_one_window(\n",
        "                    beta = betas[pref],\n",
        "                    xx = day_xx,\n",
        "                    stats = day_stats,\n",
        "                    pref = pref,\n",
        "                )\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "JDtZy7ErRRrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qikc1zYgUAh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# asof = 20251020\n",
        "# lookback = 30\n",
        "# lookforward = 5\n",
        "# target_cols = [\"y60r05\"]\n",
        "\n",
        "# IS_xx, IS_stats, OOS_xx, OOS_stats, OOS_daily = build_windows(\n",
        "#     output_path = output_path,\n",
        "#     calendar = calendar,\n",
        "#     asof = asof,\n",
        "#     lookback = lookback,\n",
        "#     lookforward = lookforward,\n",
        "#     ref_headers = ref_headers,\n",
        "#     target_cols = target_cols,\n",
        "# )\n",
        "\n",
        "# p = len(ref_headers)\n",
        "# prefixes = [f\"Y{k}_\" for k in range(len(target_cols))]\n",
        "\n",
        "# assert IS_xx.shape == (p, p)\n",
        "# assert IS_xx.dtype == np.float32\n",
        "# assert OOS_xx.shape == (p, p)\n",
        "# assert OOS_xx.dtype == np.float32\n",
        "\n",
        "# assert isinstance(OOS_daily, dict)\n",
        "# assert len(OOS_daily) == lookforward\n",
        "\n",
        "# OOS_dates = assemble_dates(calendar, asof, lookforward, \"out of sample\")\n",
        "# assert sorted(OOS_daily.keys()) == OOS_dates\n",
        "\n",
        "# for pref in prefixes:\n",
        "#     assert pref in IS_stats[\"N\"]\n",
        "#     assert pref in IS_stats[\"x_sum\"]\n",
        "#     assert pref in IS_stats[\"y_sum\"]\n",
        "#     assert pref in IS_stats[\"yy\"]\n",
        "#     assert pref in IS_stats[\"xy\"]\n",
        "\n",
        "#     assert pref in OOS_stats[\"N\"]\n",
        "#     assert pref in OOS_stats[\"x_sum\"]\n",
        "#     assert pref in OOS_stats[\"y_sum\"]\n",
        "#     assert pref in OOS_stats[\"yy\"]\n",
        "#     assert pref in OOS_stats[\"xy\"]\n",
        "\n",
        "#     assert isinstance(IS_stats[\"N\"][pref], (np.integer, int))\n",
        "#     assert isinstance(OOS_stats[\"N\"][pref], (np.integer, int))\n",
        "#     assert int(IS_stats[\"N\"][pref]) > 0\n",
        "#     assert int(OOS_stats[\"N\"][pref]) > 0\n",
        "\n",
        "#     assert IS_stats[\"x_sum\"][pref].shape == (p, )\n",
        "#     assert IS_stats[\"x_sum\"][pref].dtype == np.float32\n",
        "#     assert IS_stats[\"xy\"][pref].shape == (p, )\n",
        "#     assert IS_stats[\"xy\"][pref].dtype == np.float32\n",
        "\n",
        "#     assert OOS_stats[\"x_sum\"][pref].shape == (p, )\n",
        "#     assert OOS_stats[\"x_sum\"][pref].dtype == np.float32\n",
        "#     assert OOS_stats[\"xy\"][pref].shape == (p, )\n",
        "#     assert OOS_stats[\"xy\"][pref].dtype == np.float32\n",
        "\n",
        "# for d in OOS_dates:\n",
        "#     day_xx, day_stats = OOS_daily[d]\n",
        "#     assert day_xx.shape == (p, p)\n",
        "#     assert day_xx.dtype == np.float32\n",
        "#     for pref in prefixes:\n",
        "#         assert int(day_stats[\"N\"][pref]) > 0\n",
        "#         assert day_stats[\"x_sum\"][pref].shape == (p, )\n",
        "#         assert day_stats[\"x_sum\"][pref].dtype == np.float32\n",
        "#         assert day_stats[\"xy\"][pref].shape == (p, )\n",
        "#         assert day_stats[\"xy\"][pref].dtype == np.float32\n",
        "\n",
        "# for pref in prefixes:\n",
        "#     sum_daily_N = sum(int(OOS_daily[d][1][\"N\"][pref]) for d in OOS_dates)\n",
        "#     assert int(OOS_stats[\"N\"][pref]) == sum_daily_N\n",
        "\n",
        "#     sum_daily_x_sum = np.zeros((p, ), dtype = np.float32)\n",
        "#     sum_daily_xy = np.zeros((p, ), dtype = np.float32)\n",
        "#     for d in OOS_dates:\n",
        "#         sum_daily_x_sum += OOS_daily[d][1][\"x_sum\"][pref]\n",
        "#         sum_daily_xy += OOS_daily[d][1][\"xy\"][pref]\n",
        "\n",
        "#     assert np.allclose(OOS_stats[\"x_sum\"][pref], sum_daily_x_sum, rtol = 0, atol = 0)\n",
        "#     assert np.allclose(OOS_stats[\"xy\"][pref], sum_daily_xy, rtol = 0, atol = 0)\n",
        "\n",
        "# sum_daily_xx = np.zeros((p, p), dtype = np.float32)\n",
        "# for d in OOS_dates:\n",
        "#     sum_daily_xx += OOS_daily[d][0]\n",
        "\n",
        "# assert np.allclose(OOS_xx, sum_daily_xx, rtol = 0, atol = 0)\n"
      ],
      "metadata": {
        "id": "bSn1m6uEUCk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asof = 20251020\n",
        "lookback = 30\n",
        "lookforward = 5\n",
        "\n",
        "IS_xx, IS_stats, OOS_xx, OOS_stats, OOS_daily = build_windows(\n",
        "    output_path = output_path,\n",
        "    calendar = calendar,\n",
        "    asof = asof,\n",
        "    lookback = lookback,\n",
        "    lookforward = lookforward,\n",
        "    ref_headers = ref_headers,\n",
        "    target_cols = target_cols,\n",
        ")\n",
        "\n",
        "betas, IS_metrics = fit_from_meta(\n",
        "    IS_xx,\n",
        "    IS_stats,\n",
        "    target_cols = target_cols,\n",
        ")\n",
        "\n",
        "OOS_result = test_from_meta(\n",
        "    betas = betas,\n",
        "    OOS_xx = OOS_xx,\n",
        "    OOS_stats = OOS_stats,\n",
        "    OOS_daily = OOS_daily,\n",
        "    target_cols = target_cols,\n",
        ")"
      ],
      "metadata": {
        "id": "_GDb5is9Ub0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}